{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import datefinder #pip install datefinder if not found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(raw_text, stop_words = []):\n",
    "    ### \n",
    "    \n",
    "    # clean raw_texts by removing special character and digits.\n",
    "    # remove stop words if specified.\n",
    "    # and lemmatize followed by stem operation for each word.\n",
    "    \n",
    "    ###\n",
    "            \n",
    "    text = raw_text.replace('\\xa0', ' ').replace('\\n', ' ').lower()\n",
    "\n",
    "    # remove special characters such as the \"'\" in \"it's\".\n",
    "    text = re.sub(r'x\\.\\.\\.', 'xxx', text)\n",
    "\n",
    "    text = re.sub(r'y\\.\\.\\.', 'yyy', text)\n",
    "\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    # remove single character such as the \"s\" in \"it s\".\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "\n",
    "    # remove stop words if it's not none.\n",
    "    for w in stop_words:\n",
    "        text = re.sub(r\"\\b\" + w + r\"\\b\", '', text)\n",
    "\n",
    "    # unify successive blank space as one blank space.\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "        \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train data\n",
    "x_tr_df = pd.read_csv('train_folder/x_train_ids.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author code\n",
    "tr_dir = \"train_folder/txt_files/\"\n",
    "tr_files = x_tr_df['filename'].values\n",
    "\n",
    "\n",
    "tr_texts = []\n",
    "for tr_file in tr_files:\n",
    "    f = open(os.path.join(tr_dir, tr_file), \"r\")\n",
    "    ff = f.read()\n",
    "    ff = clean(ff)\n",
    "    tr_texts.append(ff)\n",
    "# tr_texts has all the texts in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train data\n",
    "y_tr_df = pd.read_csv('./Y_train_predilex.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexe</th>\n",
       "      <th>date_accident</th>\n",
       "      <th>date_consolidation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homme</td>\n",
       "      <td>1991-04-09</td>\n",
       "      <td>n.c.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homme</td>\n",
       "      <td>2005-06-10</td>\n",
       "      <td>2010-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>femme</td>\n",
       "      <td>1997-09-26</td>\n",
       "      <td>n.c.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>femme</td>\n",
       "      <td>1982-08-07</td>\n",
       "      <td>1982-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homme</td>\n",
       "      <td>1996-11-26</td>\n",
       "      <td>n.c.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sexe date_accident date_consolidation\n",
       "ID                                        \n",
       "0   homme    1991-04-09               n.c.\n",
       "1   homme    2005-06-10         2010-01-19\n",
       "2   femme    1997-09-26               n.c.\n",
       "3   femme    1982-08-07         1982-11-07\n",
       "4   homme    1996-11-26               n.c."
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Find sentence with date in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = []\n",
    "for i in range(len(tr_texts)):\n",
    "    if y_tr_df['date_accident'][i] != 'n.c.':\n",
    "        ff = [m.start() for m in re.finditer(y_tr_df['date_accident'][i][:4], tr_texts[i])]\n",
    "    else:\n",
    "        ff = []\n",
    "    all_dates.append(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for ind in range(len(tr_texts)):\n",
    "    sentence = []\n",
    "    window = 20\n",
    "    for date in all_dates[ind]:\n",
    "        left = tr_texts[ind][date - window : date]\n",
    "        right = tr_texts[ind][date + 4 : date + window]\n",
    "        left_num = re.findall(r'\\d', left)\n",
    "        right_num = re.findall(r'\\d', right)\n",
    "        if len(left_num) == 0 & len(right_num) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            text = tr_texts[ind][date - window : date + window]\n",
    "            sentence.append(text)\n",
    "    sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = r\"\\d+ \\w+ \\d+\"\n",
    "pattern2 = r\"1° \\w+ \\d+\"\n",
    "pattern3 = r\"1er \\w+ \\d+\"\n",
    "pattern4 = r\"\\d+\\.\\d+\\.\\d+\"\n",
    "pattern5 = r\"\\d+/\\d+/\\d+\"\n",
    "pattern6 = r\"\\d+ / \\d+ / \\d+\"\n",
    "pattern7 = r\"\\d+/ \\d+/ \\d+\"\n",
    "pattern8 = r\"\\d+\\. \\d+\\. \\d+\"\n",
    "\n",
    "patterns = [pattern1, pattern3] #, pattern3, pattern4, pattern5, pattern6, pattern7, pattern8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "fails = []\n",
    "for i in range(len(sentences)):\n",
    "    date = []\n",
    "    index = []\n",
    "    for sentence in sentences[i]:\n",
    "        l = []\n",
    "        for pattern in patterns:\n",
    "            l.extend(re.findall(pattern, sentence))\n",
    "        if len(l) == 0:\n",
    "            fails.append(sentence)\n",
    "        date.extend(l)\n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['re 1997 à septembre 1998 qu ainsi son pr',\n",
       " '2 au titre de année 2002 de sorte que le',\n",
       " ' survenu le 1o mars 2002 est pas objet d',\n",
       " 'res en 1996 puis en 1997 mme myriam yyy ',\n",
       " 'let 1996 et janvier 1997 aurait pas refu',\n",
       " 'let 1996 et janvier 1997 de sorte qu il ',\n",
       " 'tions de 1996 et de 1997 ni la qualité d',\n",
       " 'ables de 1996 et de 1997 date de consoli',\n",
       " '0 outre la somme de 2000 au titre de art',\n",
       " 'il 2008 à septembre 2008 secondairement ',\n",
       " 'obre 2007 à février 2008 ainsi que la so',\n",
       " 'mbre 2008 à février 2009 du fait de troi',\n",
       " 'conclu le 15décembre1992 que accident po',\n",
       " 's monsieur gilbert 72000 le mans la mutu',\n",
       " ' 692 euros en avril 2004 et de 1 566 eur',\n",
       " ' 1 566 euros en mai 2004 il produit deux',\n",
       " 'rier 1984 à ajaccio 20000 20160 coggia a',\n",
       " ' finosello cs 15002 20000 ajaccio cedex ',\n",
       " 'r pour 235 jours en 2002 8 ans et 6 mois',\n",
       " 'n mars 2008 et juin 2010 et il ne peut d',\n",
       " 'août 1984 à ajaccio 20090 ajaccio ayant ',\n",
       " '52 euros pour année 2006 en conséquence ',\n",
       " '999 alors que année 1999 est celle de la',\n",
       " '16 euros pour année 2002 des recettes de',\n",
       " '8 à marseille 13000 20000 ajaccio représ',\n",
       " '3 la perte de xxxen 2008 est donc 41 119',\n",
       " 'sion le 1o novembre 2009 cet expert indi',\n",
       " '06 en fin de saison 2005 2006 ce club ét',\n",
       " ' 2ème année en juin 2005 et de façon par',\n",
       " 'de 53 687 perçue en 2004 au titre de la ',\n",
       " 'anvier 2003 à avril 2003 faisant apparaî',\n",
       " 'ois 15 968 euros en 2003 10 mois soit un',\n",
       " 'ses et le 27juillet 1995 une hépatite ch',\n",
       " '98 euros pour année 1999 revenus industr',\n",
       " 'ses et le 27juillet 1995 une hépatite ch',\n",
       " 'e 48 226 pour année 1992 si on prend ann',\n",
       " '005 et fin décembre 2004 vu le jugement ',\n",
       " '00 lui été payée en 1992 par air inter p',\n",
       " 'mai 1997 et octobre 1998 malgré ses anté',\n",
       " 'mai 1997 et octobre 1998 a pas permis la',\n",
       " 'embre 1996 et avril 1997 il convient de ',\n",
       " ' de tulle 19 est en 1994 alors qu il éta',\n",
       " '9 au cours de année 2006 il été employé ',\n",
       " ' 5384 62 pour année 2011 et pour année 2',\n",
       " 'en 1985 en novembre 1999 il été diagnost',\n",
       " ' 1982 et reconnu en 1999 qu il a eu une ',\n",
       " 'ées 1980 en janvier 2009 cet état est dé',\n",
       " '2 mm qu en décembre 2009 soit près de 3 ',\n",
       " 'e de mortalité 2003 2005 avec un taux in',\n",
       " 'urvenu le 1 er juin 1994 et ce en applic',\n",
       " 'savoir le 1 er juin 1994 jusqu au parfai',\n",
       " 'splanade de france 42008 saint etienne c',\n",
       " 'ts itt 27 mois mars 2001 à août 2003 con',\n",
       " 'pour la saison 2001 2002 été victime le ',\n",
       " ' âgé de 18 ans août 1994 jusqu à décembr',\n",
       " '4 au cours de année 2004 éclaté sur un p',\n",
       " '4 au cours de année 2004 éclaté sur un p',\n",
       " 'obre 2003 à octobre 2004 il travaillé co',\n",
       " '4 au cours de année 2004 éclaté sur un p',\n",
       " '4 au cours de année 2004 éclaté sur un p',\n",
       " '4 au cours de année 2004 éclaté sur un p',\n",
       " '4 au cours de année 2004 éclaté sur un p',\n",
       " '4 au cours de année 2004 éclaté sur un p',\n",
       " 'our les années 2000 2003 elle offre 3750',\n",
       " 'e xxx en 2002 et en 2003 année de accide',\n",
       " 'nt à partir de 1995 1996 attendu que con',\n",
       " 'e 20 à compter août 2005 la consolidatio',\n",
       " 'e 10 à compter août 2005 et jusqu à sa c',\n",
       " ' 1981 à la fin août 1981 que est à juste']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pattern on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test data\n",
    "x_te_df = pd.read_csv('test_folder/x_test_ids.csv', index_col=0)\n",
    "te_dir = \"test_folder/txt_files/\"\n",
    "te_files = x_te_df['filename'].values\n",
    "te_texts = []\n",
    "for te_file in te_files:\n",
    "    f = open(os.path.join(te_dir, te_file), \"r\")\n",
    "    ff = f.read()\n",
    "    ff = clean(ff)\n",
    "    te_texts.append(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\d+ \\\\w+ \\\\d+', '1er \\\\w+ \\\\d+']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for pattern in patterns:\n",
    "    index.extend(re.finditer(pattern, tr_texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "\n",
      "--------------\n",
      "r appel agen chambre sociale audience publique du 30 avril 2002 de rg 01 00515 republique francaise au nom du peu\n",
      "--------------\n",
      "ique francaise au nom du peuple francais arret du 30 avril 2002 01 00515 yvon xxx annie xxx groupe azur assurance\n",
      "--------------\n",
      "ociale dans affaire entre monsieur yvon xxx né le 30 septembre 1955 à tonneins 47 yyy du laurier 47300 bias rep assis\n",
      "--------------\n",
      " des affaires de sécurité sociale agen en date du 12 février 2001 une part et groupe azur assurances iard 7 avenue \n",
      "--------------\n",
      "e été débattue et plaidée en audience publique le 19 mars 2002 devant monsieur milhet président de chambre madam\n",
      "--------------\n",
      "isées de la date à laquelle arrêt serait rendu le 9 avril 1991 monsieur xxx été victime un accident du travail a\n",
      "--------------\n",
      " été gravement blessé suivant jugement en date du 24 avril 1997 confirmé par arrêt de la cour en date du 30 mars \n",
      "--------------\n",
      "ril 1997 confirmé par arrêt de la cour en date du 30 mars 1999 le tribunal des affaires de sécurité sociale de l\n",
      "--------------\n",
      "confiée au docteur l expert déposé son rapport le 2 février 2 000 suivant jugement en date du 12 février 2 001 \n",
      "--------------\n",
      "rt le 2 février 2 000 suivant jugement en date du 12 février 2 001 le tribunal des affaires de sécurité sociale \n",
      "--------------\n",
      "confirmer la décision entreprise sauf à réduire à 4 573 47 euros 30 000 francs le montant de indemnité allou\n",
      "--------------\n",
      "amnation des appelants au paiement de la somme de 1 524 49 euros 10 000 francs en application des dispositio\n",
      "--------------\n",
      "sme thoracique avec fractures des arcs moyens des 5 et 6 côtes gauches un traumatisme du membre inférieur \n",
      "--------------\n",
      "des souffrances endurées quantifiées par expert à 5 5 7 été correctement fixée à 10 671 43 euros 70 000 f\n",
      "--------------\n",
      "fiées par expert à 5 5 7 été correctement fixée à 10 671 43 euros 70 000 francs par le premier juge que la ré\n",
      "--------------\n",
      "llure saccadée de la marche été justement fixée à 1 524 49 euros 10 000 francs que le préjudice agrément qui\n",
      "--------------\n",
      "initiative été à juste titre évalué à la somme de 18 293 88 euros 120 000 francs que la majoration de la rent\n",
      "--------------\n",
      " sociale limitativement énumérés aux articles 452 2 et 452 3 du code de la sécurité sociale que intéressé bé\n"
     ]
    }
   ],
   "source": [
    "window = 50\n",
    "for ind in index:\n",
    "    chunk = tr_texts[0][ind.start() - window: ind.end() + window]\n",
    "    print('--------------')\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1991-04-09'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_df['date_accident'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Using Datefinder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesnt work because Septembre is in french and wont be found by regular pattern such as 9 September\n",
    "\n",
    "matches = datefinder.find_dates(tr_texts[0], index = True)\n",
    "\n",
    "all_dates = []\n",
    "for match in matches:\n",
    "    if match[0].year > 1900 and match[0].year < 2100:\n",
    "        print(match)\n",
    "        all_dates.append(match[1])\n",
    "#all_dates\n",
    "\n",
    "all_dates\n",
    "\n",
    "ind = 9\n",
    "tr_texts[5][all_dates[ind][0]:all_dates[ind][1]]\n",
    "\n",
    "for i in range(len(tr_texts[0])):\n",
    "    if tr_texts[0][i] == '.':\n",
    "        print(i)\n",
    "\n",
    "all_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
