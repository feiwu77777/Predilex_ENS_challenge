{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author code\n",
    "x_tr_df = pd.read_csv('train_folder/x_train_ids.csv', index_col=0)\n",
    "tr_dir = \"train_folder/txt_files/\"\n",
    "tr_files = x_tr_df['filename'].values\n",
    "\n",
    "\n",
    "tr_texts = []\n",
    "for tr_file in tr_files:\n",
    "    f = open(os.path.join(tr_dir, tr_file), \"r\")\n",
    "    ff = f.read()\n",
    "    ff = clean1(ff)\n",
    "    tr_texts.append(ff)\n",
    "# tr_texts has all the texts in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train data\n",
    "y_tr_df = pd.read_csv('./Y_train_predilex.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexe</th>\n",
       "      <th>date_accident</th>\n",
       "      <th>date_consolidation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homme</td>\n",
       "      <td>1991-04-09</td>\n",
       "      <td>n.c.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homme</td>\n",
       "      <td>2005-06-10</td>\n",
       "      <td>2010-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>femme</td>\n",
       "      <td>1997-09-26</td>\n",
       "      <td>n.c.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>femme</td>\n",
       "      <td>1982-08-07</td>\n",
       "      <td>1982-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homme</td>\n",
       "      <td>1996-11-26</td>\n",
       "      <td>n.c.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sexe date_accident date_consolidation\n",
       "ID                                        \n",
       "0   homme    1991-04-09               n.c.\n",
       "1   homme    2005-06-10         2010-01-19\n",
       "2   femme    1997-09-26               n.c.\n",
       "3   femme    1982-08-07         1982-11-07\n",
       "4   homme    1996-11-26               n.c."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text without using stop words nor lemmitizer\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\" remove unwanted characters from text \"\"\"\n",
    "    # remove line breaks\n",
    "    text = text.replace('\\n', '')\n",
    "    # remove quotes\n",
    "    text = text.replace('\"', '')\n",
    "    #lowercase text\n",
    "    text = text.lower()\n",
    "    #remove punctuation and special characters ?:!.,[]();\n",
    "    text = text.translate(str.maketrans('', '', '?:!.,;[]()*-'))\n",
    "    # remove possessive pronouns termination\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    # remove unnecessery white spaces\n",
    "    text = re.sub(r\"\\s\\s+\", \" \", text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with unknow gender in training set\n",
    "gender_na_idx = y_tr_df[y_tr_df['sexe'] == 'n.c.'].index\n",
    "y_tr_df = y_tr_df[y_tr_df['sexe'] != 'n.c.']\n",
    "y_tr_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "tr_texts = [clean_text(tr_texts[i]) for i in range(len(tr_texts)) if i not in gender_na_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 2), max_features=100, norm='l2', sublinear_tf=True)\n",
    "x_train = tfidf_vec.fit_transform(tr_texts)\n",
    "y_train = y_tr_df['sexe'].map({'homme': 1, 'femme': 0}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for class 0: 206\n",
      "Number of samples for class 1: 559\n"
     ]
    }
   ],
   "source": [
    "c_val, c_count = np.unique(y_train, return_counts=True)\n",
    "for i, c in enumerate(c_val):\n",
    "    print(f\"Number of samples for class {c}: {c_count[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cv(cls, cv=3):\n",
    "    cv_results = cross_validate(cls, x_train, y_train, scoring='accuracy', return_train_score=True, cv=cv)\n",
    "    print(f\"CV Accuracy: {round(cv_results['train_score'].mean() * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(cls, param_grid):\n",
    "    \"\"\" perform a grid search on a classifier using 3-fold cross validation and the passed prameters \"\"\"\n",
    "    grid_search = GridSearchCV(estimator=cls, \n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=3,\n",
    "                               verbose=1)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print(f\"The best hyperparameters from Grid Seach are: {grid_search.best_params_}\")\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Seach are: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 5, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:   11.9s finished\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [.01, .1],\n",
    "    'subsample': [.7, .9, 1],\n",
    "    'colsample_bytree': [.7, .9, 1],\n",
    "}\n",
    "xgb_cls = XGBClassifier(random_state=random_state)\n",
    "xgb_cls = perform_grid_search(xgb_cls, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "apply_cv(xgb_cls, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=0.9, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cls.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test data\n",
    "x_te_df = pd.read_csv('test_folder/x_test_ids.csv', index_col=0)\n",
    "te_dir = \"test_folder/txt_files/\"\n",
    "te_files = x_te_df['filename'].values\n",
    "te_texts = []\n",
    "\n",
    "for te_file in te_files:\n",
    "    f = open(os.path.join(te_dir, te_file), \"r\")\n",
    "    ff = f.read()\n",
    "    ff = clean1(ff)\n",
    "    ff = clean_text(ff)\n",
    "    te_texts.append(ff)\n",
    "# tr_texts has all the texts in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tfidf_vec.transform(te_texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = xgb_cls.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('results/gender.npy', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
